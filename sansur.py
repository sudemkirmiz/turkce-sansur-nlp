import spacy
import os
from TurkishStemmer import TurkishStemmer

# Spacy: Kelimeleri ayÄ±rmak iÃ§in (Tokenization)
try:
    nlp = spacy.blank("tr")
except:
    nlp = spacy.blank("xx")

# Stemmer: Kelime kÃ¶kÃ¼ bulmak iÃ§in
stemmer = TurkishStemmer()

# Dosya YollarÄ±
KLASOR = os.path.dirname(os.path.abspath(__file__))
BLACKLIST_PATH = os.path.join(KLASOR, "yasakli_kelimeler.txt")

def load_blacklist(path):
    """YasaklÄ± kelimeleri dosyadan okur ve bir kÃ¼me (set) olarak dÃ¶ndÃ¼rÃ¼r."""
    words = set()
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            for line in f:
                if line.strip().startswith("#"): continue # Yorum satÄ±rlarÄ±nÄ± atla
                w = line.strip().lower()
                if w:
                    words.add(w)
    else:
        print("UYARI: yasakli_kelimeler.txt bulunamadÄ±!")
    return words

# Listeyi hafÄ±zaya yÃ¼kle
yasaklar = load_blacklist(BLACKLIST_PATH)

def is_toxic(token):
    """Bir kelimenin yasaklÄ± olup olmadÄ±ÄŸÄ±nÄ± 3 aÅŸamada kontrol eder."""
    kelime_ham = token.text.lower()
    
    # 1. AÅŸama: Birebir eÅŸleÅŸme (HÄ±zlÄ± kontrol)
    if kelime_ham in yasaklar:
        return True
    
    # 2. AÅŸama: NoktalÄ± sansÃ¼rden kaÃ§ma kontrolÃ¼
    kelime_noktasiz = kelime_ham.replace(".", "")
    if kelime_noktasiz in yasaklar and len(kelime_noktasiz) > 1:
        return True

    # 3. AÅŸama: Stemming (KÃ¶k bulma)
    kelime_kok = stemmer.stem(kelime_ham)
    if kelime_kok in yasaklar:
        # HATA Ã–NLEYÄ°CÄ°: KÃ¶k "normal" gibi masum bir kelimeyle Ã§akÄ±ÅŸmasÄ±n.
        # Ã–rn: "analiz" kelimesinin kÃ¶kÃ¼ "anal" Ã§Ä±kabilir (hatalÄ± stemmer durumunda).
        # KÄ±sa kelimelerde (3 harften az) kÃ¶k kontrolÃ¼nÃ¼ sadece belli kelimeler iÃ§in yap.
        if len(kelime_kok) < 3 and kelime_kok not in ["aq", "oÃ§", "am", "sik"]:
            return False 
        return True

    return False

def censor(metin):
    """Metni alÄ±r, yasaklÄ± kelimeleri yÄ±ldÄ±zlar ve geri dÃ¶ndÃ¼rÃ¼r."""
    doc = nlp(metin) #dÃ¼z split() fonksiyonu sadece boÅŸluktan ayÄ±rÄ±r. spaCy ise noktalama iÅŸaretlerini, virgÃ¼lleri de ayÄ±rÄ±r.
    yeni_metin = []
    
    for t in doc:
        if is_toxic(t):
            # Kelime uzunluÄŸu kadar yÄ±ldÄ±z koy, boÅŸluklarÄ± koru
            yeni_metin.append("*" * len(t.text) + t.whitespace_)
        else:
            yeni_metin.append(t.text_with_ws)
            
    return "".join(yeni_metin)

# --- 4. Ã‡ALIÅTIRMA ---
if __name__ == "__main__":
    print("="*50)
    print(f"SANSÃœR SÄ°STEMÄ°")
    print(f"VeritabanÄ±: {len(yasaklar)} kelime yÃ¼klendi")
    print("="*50)
    
    while True:
        try:
            sarki = input("\nğŸµ ÅarkÄ± sÃ¶zÃ¼ gir (Ã‡Ä±kÄ±ÅŸ iÃ§in 'q'): ")
        except KeyboardInterrupt:
            break

        if sarki.lower() in ["q", "exit", "kapat"]:
            print("Sistem kapatÄ±lÄ±yor...")
            break
        
        if not sarki.strip():
            continue
            
        sonuc = censor(sarki)
        print(f" SONUÃ‡: {sonuc}")